{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2-59ODRAn-T"
      },
      "source": [
        "# RAGを用いた業務改善シナリオ\n",
        "\n",
        "## シナリオの概要\n",
        "ある打合せで決まったネクストアクションに関して、情報収集とレポーティングをサポートする\n",
        "\n",
        "- Step1- ①動画の内容（今回は記者会見）からネクストアクションの抽出を行う\n",
        "\n",
        "- Step2- ②動画からネクストアクションの抽出を行う\n",
        "\n",
        "- Step3- ③ネクストアクションに関連する社内・社外情報を収集する。\n",
        "\n",
        "- Step4④ネクストアクションに応じて情報をまとめる。\n",
        "\n",
        "- Step5⑤各種フォーマット（ppt, word等）で資料を作成する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYAB8YtSwVj4"
      },
      "source": [
        "# 事前準備：必要なソフトウェアをインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U-A_7rzHvhMC",
        "outputId": "90478a66-243a-48e5-c526-f11aa0942faa"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install langchain-openai\n",
        "!pip install python-pptx python-docx\n",
        "!pip install unstructured\n",
        "!pip install faiss-gpu\n",
        "!pip install requests\n",
        "!pip install moviepy\n",
        "!pip install --upgrade moviepy\n",
        "!pip install pypdf\n",
        "!pip install getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q2x74ntPJKM"
      },
      "source": [
        "# Step1- ①動画の内容（今回は記者会見）からネクストアクションの抽出を行う\n",
        "## 動画データ（YouTube）をテキストデータに変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCUDFOkwIi-p"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "def process_video_trim_upload(input_video_path, API_KEY, output_audio_path=\"/content/video.mp3\", max_duration=1000):\n",
        "    \"\"\"\n",
        "    動画から音声を抽出し、Gladia APIを使用して音声をアップロードおよび転写します。\n",
        "\n",
        "    :param input_video_path: 入力動画ファイルのパス\n",
        "    :param API_KEY: Gladia APIのAPIキー\n",
        "    :param output_audio_path: 出力音声ファイルのパス（デフォルトは \"/content/video.mp3\"）\n",
        "    :param max_duration: 最大音声時間（秒）。デフォルトは600秒（10分）\n",
        "    :param polling_interval: ポーリングの間隔（秒）。デフォルトは10秒\n",
        "    :param max_attempts: 最大ポーリング試行回数。デフォルトは30回（約5分）\n",
        "    :return: 転写されたデータ（辞書形式）またはエラーメッセージ\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. 動画から音声を抽出\n",
        "        print(\"動画から音声を抽出中...\")\n",
        "        video = VideoFileClip(input_video_path)\n",
        "        audio = video.audio\n",
        "\n",
        "        if audio is None:\n",
        "            return {\"error\": \"この動画には音声が含まれていません。\"}\n",
        "\n",
        "        duration = audio.duration\n",
        "        print(f\"音声の総時間: {duration} 秒\")\n",
        "\n",
        "        if duration > max_duration:\n",
        "            print(f\"音声が{max_duration/60}分を超えているため、最初の{max_duration/60}分のみを保存します。\")\n",
        "            audio = audio.subclip(0, max_duration)\n",
        "\n",
        "        # 音声を一時ファイルに書き出す\n",
        "        audio.write_audiofile(output_audio_path)\n",
        "        print(f\"音声が正常に保存されました: {output_audio_path}\")\n",
        "\n",
        "        # 2. 音声ファイルをGladia APIにアップロード\n",
        "        print(\"音声ファイルをアップロード中...\")\n",
        "        upload_url = \"https://api.gladia.io/v2/upload\"\n",
        "        files = {'audio': (output_audio_file, open(output_audio_file, 'rb'), 'audio/mpeg')}\n",
        "        headers = {\n",
        "            \"x-gladia-key\": API_KEY\n",
        "        }\n",
        "        upload_response = requests.post(upload_url, files=files, headers=headers)\n",
        "\n",
        "        if upload_response.status_code != 200:\n",
        "            return {\"error\": f\"アップロードに失敗しました: {upload_response.text}\"}\n",
        "\n",
        "        upload_json = upload_response.json()\n",
        "        audio_url = upload_json.get(\"audio_url\")\n",
        "        if not audio_url:\n",
        "            return {\"error\": \"アップロードされた音声のURLが取得できませんでした。\"}\n",
        "\n",
        "        print(f\"音声がアップロードされました: {audio_url}\")\n",
        "        return audio_url\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"エラーが発生しました: {str(e)}\"}\n",
        "\n",
        "def request_transcription(audio_url, API_KEY):\n",
        "    # 3. 転写リクエストを送信\n",
        "    print(\"書き起こしリクエストを送信中...\")\n",
        "    transcription_url = \"https://api.gladia.io/v2/transcription\"\n",
        "    transcription_data = {\n",
        "      \"audio_url\": audio_url,\n",
        "        \"diarization\": True,\n",
        "        \"diarization_config\": {\n",
        "            \"number_of_speakers\": 2,\n",
        "            \"min_speakers\": 1,\n",
        "            \"max_speakers\": 5\n",
        "        },\n",
        "        # 必要に応じて以下のオプションを有効化できます\n",
        "        # \"translation\": True,\n",
        "        # \"translation_config\": {\n",
        "        #     \"model\": \"base\",\n",
        "        #     \"target_languages\": [\"fr\", \"en\"]\n",
        "        # },\n",
        "        # \"subtitles\": True,\n",
        "        # \"subtitles_config\": {\n",
        "        #     \"formats\": [\"srt\", \"vtt\"]\n",
        "        # },\n",
        "        \"detect_language\": True,\n",
        "        \"enable_code_switching\": False\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'x-gladia-key': API_KEY,\n",
        "    }\n",
        "\n",
        "    transcription_response = requests.post(transcription_url, headers=headers, data=json.dumps(transcription_data))\n",
        "\n",
        "    transcription_json = transcription_response.json()\n",
        "    print(\"書き起こしリクエスト完了しました。ID:\"+ transcription_json[\"id\"])\n",
        "    return transcription_json\n",
        "\n",
        "\n",
        "def get_transcription_result(transcribed_data, api_key, poll_interval=10, max_retries=60):\n",
        "    \"\"\"\n",
        "    トランスクリプションの結果が 'done' になるまでポーリングします。\n",
        "\n",
        "    :param transcribed_data: トランスクリプション要求のレスポンスデータ（辞書型）\n",
        "    :param api_key: Gladia APIキー\n",
        "    :param poll_interval: ポーリング間隔（秒）\n",
        "    :param max_retries: 最大リトライ回数\n",
        "    :return: トランスクリプション結果のデータ（辞書型）またはNone\n",
        "    \"\"\"\n",
        "    result_id = transcribed_data[\"id\"]\n",
        "    if not result_id:\n",
        "        print(\"エラー: 'id' が transcribed_data に含まれていません。\")\n",
        "        return None\n",
        "\n",
        "    url = f\"https://api.gladia.io/v2/transcription/{result_id}\"\n",
        "    headers = {\"x-gladia-key\": api_key}\n",
        "\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"エラー: APIリクエストが失敗しました。ステータスコード: {response.status_code}\")\n",
        "                print(f\"レスポンス内容: {response.text}\")\n",
        "                return None\n",
        "\n",
        "            result_data = response.json()\n",
        "            status = result_data.get('status')\n",
        "\n",
        "            print(f\"現在のステータス: {status}\")\n",
        "\n",
        "            if status == 'done':\n",
        "                print(\"トランスクリプションが完了しました。\")\n",
        "                return result_data\n",
        "            elif status in ['failed', 'canceled']:\n",
        "                print(f\"トランスクリプションが '{status}' 状態で終了しました。\")\n",
        "                return None\n",
        "            else:\n",
        "                print(f\"トランスクリプションはまだ完了していません。{poll_interval}秒後に再試行します。\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"リクエスト中にエラーが発生しました: {e}\")\n",
        "            return None\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"レスポンスのJSON解析中にエラーが発生しました。\")\n",
        "            return None\n",
        "\n",
        "        retries += 1\n",
        "        time.sleep(poll_interval)\n",
        "\n",
        "    print(\"最大リトライ回数に達しました。トランスクリプションが完了していません。\")\n",
        "    return None\n",
        "\n",
        "def process_transcription(result_data, output_file_path):\n",
        "    \"\"\"\n",
        "    トランスクリプションデータを処理し、スピーカーごとにテキストファイルに出力します。\n",
        "\n",
        "    :param result_data: トランスクリプション結果のデータ（辞書型）\n",
        "    :param output_file_path: 出力するテキストファイルのパス\n",
        "    \"\"\"\n",
        "    # 現在のスピーカーのIDを保持する変数を初期化\n",
        "    current_speaker = None\n",
        "    # 現在のスピーカーのトランスクリプトを保持する変数を初期化\n",
        "    current_transcript = \"\"\n",
        "\n",
        "    # 出力ファイルを開く（上書きモード）\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        # utterancesをループして各発話を処理\n",
        "        for u in result_data[\"result\"][\"transcription\"][\"utterances\"]:\n",
        "            # 現在のスピーカーが前のスピーカーと同じ場合\n",
        "            if u[\"speaker\"] == current_speaker:\n",
        "                # トランスクリプトを結合\n",
        "                current_transcript += \" \" + u[\"text\"]\n",
        "            else:\n",
        "                # 現在のスピーカーが前のスピーカーと異なる場合（または最初の発話の場合）\n",
        "                if current_speaker is not None:\n",
        "                    # 前のスピーカーのトランスクリプトをファイルに書き込む\n",
        "                    f.write(f\"[Speaker: {current_speaker}] {current_transcript}\\n\")\n",
        "\n",
        "                # 新しいスピーカーのIDとトランスクリプトを更新\n",
        "                current_speaker = u[\"speaker\"]\n",
        "                current_transcript = u[\"text\"]\n",
        "\n",
        "        # 最後のスピーカーのトランスクリプトをファイルに書き込む\n",
        "        if current_transcript:\n",
        "            f.write(f\"[Speaker: {current_speaker}] {current_transcript}\\n\")\n",
        "            print(f\"[Speaker: {current_speaker}] {current_transcript}\")\n",
        "\n",
        "    print(f\"トランスクリプション結果が '{output_file_path}' に保存されました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Txd8GKtHhM",
        "outputId": "2d684707-5ce1-4e14-f140-9fd5dc202546"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "# APIキーを安全に入力\n",
        "api_key = getpass(\"OpenAIのAPIキーを入力してください: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "api_key = getpass(\"GRADIAのAPIキーを入力してください: \")\n",
        "os.environ[\"GR_API_KEY\"] = api_key\n",
        "GR_API_KEY = os.getenv(\"GR_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eQM3w8maIi7f",
        "outputId": "a6871224-4ffe-4dda-fa77-78bfc19ffd5e"
      },
      "outputs": [],
      "source": [
        "#ここで事前お配りしたファイルを左のフォルダにアップロードしていただけると助かります！\n",
        "\n",
        "\n",
        "#動画ファイルのパスは左のファイル部分でお願いします\n",
        "audio_file= \"/content/testmovie.mp4\"\n",
        "# audio_file= \"/content/2024ビジネスアップデート.mp4\"\n",
        "output_audio_file = \"/content/video.mp3\"\n",
        "OUTPUT_FILE_PATH=\"/content/transcribed_text.txt\"\n",
        "\n",
        "audio_url = process_video_trim_upload(audio_file, GR_API_KEY)\n",
        "transcription_response = request_transcription(audio_url, GR_API_KEY)\n",
        "result_data = get_transcription_result(transcription_response, GR_API_KEY)z\n",
        "process_transcription(result_data, OUTPUT_FILE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkMMUaCfC1xb"
      },
      "source": [
        "# Step2- ②動画からネクストアクションの抽出を行う\n",
        "## 書き起こしデータからネクストアクションの抽出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X08ffTMmAvTJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# OpenAI APIキーの設定\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"sk-KlvCw7CI3UmHnyztvFslkMT0E8pLhfnA4HXB6uBiD8T3BlbkFJNI2-wy1yA1PkA_xuM5HSS1-ltrwvJaupbKvtE51fwA\"\n",
        "model_name='gpt-4o-mini'\n",
        "\n",
        "def initialize_llm(temperature=0.0, model_name=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    ChatOpenAIモデルを初期化します。\n",
        "    \"\"\"\n",
        "    # OpenAI APIキーの設定（環境変数を使用）\n",
        "    api_key = os.environ.get('OPENAI_API_KEY')\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 'OPENAI_API_KEY' を設定してください。\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # ChatOpenAIクライアントを初期化\n",
        "    llm = ChatOpenAI(temperature=temperature, model_name=model_name)\n",
        "    return llm\n",
        "\n",
        "def read_transcription(file_path):\n",
        "    \"\"\"\n",
        "    指定されたパスから書き起こしテキストを読み込みます。\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"ファイルが見つかりません: {file_path}\")\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        transcription_text = file.read()\n",
        "    return transcription_text\n",
        "\n",
        "def split_text(text, chunk_size=5000, chunk_overlap=1000):\n",
        "    \"\"\"\n",
        "    テキストを指定されたチャンクサイズとオーバーラップで分割します。\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    text_chunks = text_splitter.split_text(text)\n",
        "    return text_chunks\n",
        "\n",
        "def summarize_chunks(llm, text_chunks):\n",
        "    \"\"\"\n",
        "    各チャンクを要約します。\n",
        "    \"\"\"\n",
        "    summaries = []\n",
        "    prompt_template = \"\"\"\n",
        "        以下のテキストの要点をまとめてください。\n",
        "        テキスト:\n",
        "        \\\"\\\"\\\"\n",
        "        {text}\n",
        "        \\\"\\\"\\\"\n",
        "        要約:\n",
        "        \"\"\"\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    for chunk in text_chunks:\n",
        "        summary = chain.run(chunk)\n",
        "        summaries.append(summary.strip())\n",
        "    return summaries\n",
        "\n",
        "def generate_final_actions(llm, combined_summary):\n",
        "    \"\"\"\n",
        "    結合された要約から5つの具体的なアクションを生成します。\n",
        "    \"\"\"\n",
        "    final_prompt_template = \"\"\"\n",
        "      あなたは優秀なビジネスアナリストです。\n",
        "      以下の要約を読み、企画部がEVに関する市場動向を立てるために必要な5つの具体的なアクションをリスト形式で提案してください。\n",
        "\n",
        "      要約:\n",
        "      \\\"\\\"\\\"\n",
        "      {summary}\n",
        "      \\\"\\\"\\\"\n",
        "\n",
        "      出力形式:\n",
        "      1. アクション1\n",
        "      2. アクション2\n",
        "      3. アクション3\n",
        "      4. アクション4\n",
        "      5. アクション5\n",
        "      \"\"\"\n",
        "    prompt = PromptTemplate(template=final_prompt_template, input_variables=[\"summary\"])\n",
        "    final_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    actions_text = final_chain.run(combined_summary)\n",
        "    return actions_text\n",
        "\n",
        "def parse_actions(actions_text):\n",
        "    \"\"\"\n",
        "    LLMからの出力をパースしてアクションのリストを取得します。\n",
        "    \"\"\"\n",
        "    pattern = r'\\d+\\.\\s*(.*)'\n",
        "    actions_list = re.findall(pattern, actions_text)\n",
        "    return actions_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "D3jT7-56HdfH"
      },
      "outputs": [],
      "source": [
        "# LLMを初期化\n",
        "llm = initialize_llm()\n",
        "\n",
        "# 書き起こしテキストを読み込む\n",
        "transcription_file_path = \"/content/transcribed_text.txt\"\n",
        "#意図していない場所に生成された場合\n",
        "# transcription_file_path = \"./content/transcribed_text.txt\"\n",
        "\n",
        "transcription_text = read_transcription(transcription_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDqEiXmuULQF",
        "outputId": "147e19ec-cb75-4f9b-c7e5-caf528614ab9"
      },
      "outputs": [],
      "source": [
        "# テキストを分割\n",
        "text_chunks = split_text(transcription_text)\n",
        "\n",
        "# 各チャンクを要約\n",
        "summaries = summarize_chunks(llm, text_chunks)\n",
        "\n",
        "# 要約を結合\n",
        "combined_summary = \"\\n\".join(summaries)\n",
        "\n",
        "# 最終的なアクションを生成\n",
        "actions_text = generate_final_actions(llm, combined_summary)\n",
        "\n",
        "# アクションをリスト形式にパース\n",
        "actions_list = parse_actions(actions_text)\n",
        "\n",
        "# 結果を表示\n",
        "print(\"企画部が取るべき5つのアクション:\")\n",
        "for idx, action in enumerate(actions_list, 1):\n",
        "    print(f\"{idx}. {action}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYJzXHNhkaq7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# actions_listをDataFrameに変換し、データフレームとして表示\n",
        "df = pd.DataFrame({'actions': actions_list})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9UUAv-j7n1fC",
        "outputId": "93a29124-6ebe-4aa0-8e51-073fe364ee64"
      },
      "outputs": [],
      "source": [
        "# データフレームの中を表示\n",
        "# これで議事録の録画ファイルからネクストアクションを取り出しました（今回は５つにしています\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wbn-uj1psG0"
      },
      "source": [
        "# Step2: RAG用の検索クエリの作成\n",
        "さきほど動画からネクストアクションまで落とすことができたため、ここからアクションごとにどのようなクエリーを出せばよいかもChatGPTに作成してもらいます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af8jnKqxprVr"
      },
      "outputs": [],
      "source": [
        "# タスクから質問を作る関数\n",
        "def create_RAG_query(text_action):\n",
        "    llm = ChatOpenAI(temperature=0.0, model=model_name)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text_action\"],\n",
        "        template=\"\"\"\n",
        "        以下の情報収集タスクを実行するために、chatGPTを使ったRAGシステムに問い合わせるための質問を１つだけ作成して下さい。その際はRAGのクエリーとして最適な文章とし精度が高くなるようなクエリーにしてください。情報が不足している場合、情報を補ってよりよいクエリーを生成してください。\n",
        "        ### 情報収集タスク:\n",
        "        　{text_action}\n",
        "        \"\"\"\n",
        "    )\n",
        "    #★★このプロンプトはより高度で精度が高くなるプロンプトにすることが重要ですので、適宜上記のプロンプトを変更してください。\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    query = chain.run(text_action=text_action)\n",
        "    return query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgQi_g4Yqswp"
      },
      "outputs": [],
      "source": [
        "# pandasの各行について、create_RAG_queryを実行し、rag_queryという列名で追加\n",
        "df['rag_query'] = df['actions'].apply(create_RAG_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "4kNRH4Doq4Vo",
        "outputId": "292e1d46-0495-461d-fcc8-29491d10c062"
      },
      "outputs": [],
      "source": [
        "# RAGに問い合わせるクエリーがきちんと作成できているか、結果を確認する\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOFN8i7SVRTM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpXBxv-PPdi5"
      },
      "source": [
        "# Step3:情報の検索とまとめ：RAGの実行\n",
        "さきほど作成したクエリーをもとにRAGシステムにクエリーを投げていきます。\n",
        "今回はPDFを対象としていますが、本来は複数ファイルやフォルダごとやストレージ（onedrive, Sharepoint)などでも対応できます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw4ikM6lvVYF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFy4VaSgvmwK"
      },
      "outputs": [],
      "source": [
        "# PDFのデータベース化（こちらも事前にお配りしたtoyota.pdfを使います\n",
        "# 今回は混乱を避けるために１ファイルにしますが、複数ファイルでも問題ありません\n",
        "loader = PyPDFLoader(\"/content/toyota.pdf\")\n",
        "\n",
        "#へんなところにファイルがある場合\n",
        "# loader = PyPDFLoader(\"./content/toyota.pdf\")\n",
        "\n",
        "# loader = PyPDFLoader(\"/content/toyota_2024_4q_presentation_jp.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tDLuQW7vow-",
        "outputId": "dbe798ee-820f-4f30-c869-6fcae7efcb1c"
      },
      "outputs": [],
      "source": [
        "pages = loader.load_and_split()\n",
        "# ページ指定を変えると中身がわかります（例：1 -> 2\n",
        "pages[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2r9VMqJvr7n"
      },
      "outputs": [],
      "source": [
        "# この情報をベクトル化していき、キーワードの合致ではなく、意味の近さで検索するようにします\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(pages, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtHQA4dVvw0V",
        "outputId": "59646350-05d8-4cf3-de07-3076fc9238e4"
      },
      "outputs": [],
      "source": [
        "# ベクトルの次元数を取得（インデックスから取得）\n",
        "vector_dimension = vectorstore.index.d\n",
        "print(f\"ベクトルの次元数: {vector_dimension}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfrnxFRDvudP",
        "outputId": "7d03a078-d463-430e-cd23-6651bb6eb244"
      },
      "outputs": [],
      "source": [
        "# ベクトル情報の確認\n",
        "vectors = vectorstore.index.reconstruct_n(0, vectorstore.index.ntotal)\n",
        "\n",
        "# 最初のいくつかのベクトルを表示\n",
        "for i, vector in enumerate(vectors[:5]):\n",
        "    print(f\"Vector {i}: {vector}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohdSzhpPvZ8U"
      },
      "outputs": [],
      "source": [
        "# RAGシステムを使用して関連情報の参照先と回答結果を取得する関数\n",
        "def search_related_information(query, documents):\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    # リトリーバーの生成\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    # ベクトルストアから情報を取得\n",
        "    qa = RetrievalQA.from_chain_type(\n",
        "        llm=ChatOpenAI(model=model_name),\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    result = qa({\"query\": query})\n",
        "    # 参照先のドキュメント情報を取得\n",
        "    documents = result['source_documents']\n",
        "    # ドキュメントから関連度の最も高いページの内容を取得\n",
        "    page_content = documents[0].page_content\n",
        "    # 参照先の情報を表示\n",
        "    print(\"source_file:\",documents[0].metadata['source'])\n",
        "    print(\"source_content:\",page_content)\n",
        "    # 回答結果を取得\n",
        "    answer = result['result']\n",
        "    return page_content\n",
        "\n",
        "def create_RAG_answer(rag_query,reference_text):\n",
        "    llm = ChatOpenAI(temperature=0.0, model=model_name)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"rag_query\",\"reference_text\"],\n",
        "        template=\"\"\"\n",
        "        下記の質問について、参照情報を参考して回答して下さい。\n",
        "        ### 質問\n",
        "          {rag_query}\n",
        "        ### 参照情報:\n",
        "        　{reference_text}\n",
        "        \"\"\"\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    answer = chain.run(rag_query=rag_query, reference_text=reference_text)\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an_2dQSsuzpo",
        "outputId": "53b888ed-3940-4479-d46f-f1f8c5815639"
      },
      "outputs": [],
      "source": [
        "# 先ほど作成したRAG用のクエリを実行し、RAGの参照先のデータを取得\n",
        "# pandasの各行について、create_RAG_queryを実行し、rag_queryという列名でDataFrameに新しい列を追加\n",
        "df['reference_text'] = df['rag_query'].apply(\n",
        "    lambda x: pd.Series(search_related_information(x, pages))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE1S8Zu395HM"
      },
      "outputs": [],
      "source": [
        "# RAGの参照先のデータを利用し、回答を生成\n",
        "# rag_answerという列名でDataFrameに新しい列を追加\n",
        "df['rag_answer'] = df.apply(lambda row: create_RAG_answer(row['rag_query'], row['reference_text']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "sAZce5s-vNtp",
        "outputId": "fd866c5f-31c5-4dbf-9562-10bc87079ddd"
      },
      "outputs": [],
      "source": [
        "#実際のデータの中身がどうなったか確認します\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06glB2cZx6Uu"
      },
      "outputs": [],
      "source": [
        "# この時点でCSVにも出力しておきます\n",
        "df.to_csv(\"rag.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms4tBTPkDDky"
      },
      "source": [
        "# Step4: 適切なフォーマットに変換していく（例：パワーポイントの作成\n",
        "これまでの工程では、録画ファイルからネクストアクションを抽出し、ネクストアクションからRAGで利用するクエリーを作成。\n",
        "そこから実際にファイルやフォルダにアクセスし、「参照する文章」「RAGとして問い合わせた回答」を取得しました。\n",
        "実際の業務効率化を考えた場合、pptやwordやメールを使う機会が多いと思いますので、そのフォーマットに変換することを考えます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "BlCw4oybULQH",
        "outputId": "3c45da1b-34b2-48a5-b258-85ee2812e896"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 日本語の説明: rag.csvというCSVファイルを読み込み、必要なデータ部分だけdfの中に入れます。\n",
        "df = pd.read_csv('rag.csv', usecols=['actions', 'rag_query', 'reference_text', 'rag_answer'])\n",
        "\n",
        "df.head(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmiRyn-wULQH"
      },
      "outputs": [],
      "source": [
        "# 上でいれているので、飛ばしてOKです！\n",
        "#今回はAPIキーを直接入力するために、このようなおまじないをいれます。これを走らせると、キーの入力が求めれます。\n",
        "\n",
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "# APIキーを安全に入力\n",
        "api_key = getpass(\"OpenAIのAPIキーを入力してください: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKU6XVEsULQH",
        "outputId": "51bdf42c-c426-40f5-c56b-d1ad5d714147"
      },
      "outputs": [],
      "source": [
        "# 日本語の説明: dfに対して、formatというカラムを追加し、\"ppt\", \"word\", \"mail\"を行の数だけ入力します。\n",
        "formats = []\n",
        "\n",
        "# 各行に対してフォーマットを入力\n",
        "for i in range(len(df)):\n",
        "    format_input = input(f\"行 {i+1} のフォーマットを入力してください (ppt, word, mail): \")\n",
        "    while format_input not in [\"ppt\", \"word\", \"mail\"]:\n",
        "        print(\"無効な入力です。'ppt', 'word', 'mail'のいずれかを入力してください。\")\n",
        "        format_input = input(f\"行 {i+1} のフォーマットを入力してください (ppt, word, mail): \")\n",
        "    formats.append(format_input)\n",
        "\n",
        "df['format'] = formats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu15QkIAULQH",
        "outputId": "e879cdb5-8805-46d8-8f2d-f6caf1db3509"
      },
      "outputs": [],
      "source": [
        "# 日本語の説明: target_deptとkey_manを定義し、インプット関数で今回のターゲットを定義します。\n",
        "\n",
        "# ターゲット部門とキーマンをユーザーに入力してもらう\n",
        "target_dept = input(\"ターゲット部門を入力してください: \")\n",
        "key_man = input(\"キーマンや役職を入力してください: \")\n",
        "\n",
        "# 入力された値を表示\n",
        "print(f\"ターゲット部門: {target_dept}\")\n",
        "print(f\"キーマン: {key_man}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDnYo1hOULQH"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "# chatGPTに質問する\n",
        "# OpenAIクライアントの初期化\n",
        "client = OpenAI()\n",
        "\n",
        "# 日本語の説明: ChatGPTでrag_answerのテキストをインプットにし、format_textにGPT4oで変換します。\n",
        "\n",
        "def format_text(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",  # GPT-4oのモデル名\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"あなたは優秀なAIアシスタントです。\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# promptは可変とし、下でフォーマットごとのプロンプトを作成する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxaQqp2vULQH",
        "outputId": "32ee0098-c438-47c4-d67c-329b7a01a50f"
      },
      "outputs": [],
      "source": [
        "# 日本語の説明: dfの各行に対して、formatカラムの値に応じてGPT-4oのプロンプトを生成し、format_text関数を使用して変換します。\n",
        "\n",
        "# 各行に対して処理を行う\n",
        "for i, row in df.iterrows():\n",
        "    # rag_answerを取得\n",
        "    rag_answer = df['rag_answer'].iloc[i]\n",
        "    print(\"□□□□□□□□□\")\n",
        "    print(\"RAGの文章を変更していきます：\", rag_answer)\n",
        "\n",
        "    # formatに応じてプロンプトを生成\n",
        "    if row['format'] == 'ppt':\n",
        "        user_prompt = f'''\n",
        "        {target_dept}の{key_man}様へ提出するプレゼンテーションを作成してください。以下の内容を要点にまとめ、効果的なスライドを作成します。スライドは「スライドタイトル」「キーメッセージ」「ボディ」として構成し、どのような図解を入れるべきかも指示してください。\n",
        "        # 内容: {rag_answer}\n",
        "        '''\n",
        "    elif row['format'] == 'word':\n",
        "        user_prompt = f'''\n",
        "        {target_dept}の{key_man}様へ送る報告書を作成してください。以下の内容を4部構成で書いてください。\n",
        "        導入、分析、提案、結論を含む形式で記述します。マークダウン記法で記載し、PREP法を意識してください。\n",
        "        内容: {rag_answer}\n",
        "        '''\n",
        "    elif row['format'] == 'mail':\n",
        "        user_prompt = f'''\n",
        "        {target_dept}の{key_man}様へ送るメールを作成してください。次のステップを提案する内容です。\n",
        "        件名、挨拶、本文、締めの言葉を含め、丁寧かつ簡潔にまとめてください。\n",
        "        内容: {rag_answer}\n",
        "        '''\n",
        "\n",
        "    # GPT-4oでテキストを変換\n",
        "    try:\n",
        "        print(user_prompt)\n",
        "        formatted_text = format_text(user_prompt)\n",
        "    except UnicodeEncodeError as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "        formatted_text = \"エラー: テキストの変換に失敗しました。\"\n",
        "\n",
        "    # 変換されたテキストを新しいカラムに追加\n",
        "    df.at[i, 'format_text'] = formatted_text\n",
        "    print(\"■■■■■■■■■■■\")\n",
        "    print(f\"行目: {i}, フォーマット: {row['format']}, 変換されたテキスト:\\n{formatted_text}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "3iXvggx8ULQH",
        "outputId": "24ffbaa8-4b1a-490b-cb9c-7f51c0d17e33"
      },
      "outputs": [],
      "source": [
        "# 実際に出力する\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDkxii04ULQI"
      },
      "source": [
        "# Step5: 各種フォーマット（ppt, word等）で資料を作成する。\n",
        "ここからは、これまで作成したものを使わず、pptやワードで資料が作成できることをお見せします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo3XAQEYx6_D"
      },
      "outputs": [],
      "source": [
        "input_data = f\"\"\"\n",
        "目的：{df[\"actions\"][0]}\n",
        "\n",
        "情報：{df[\"rag_answer\"][0]}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9A1LYQZyY-H",
        "outputId": "f16dd3de-2269-43f0-c182-444576911332"
      },
      "outputs": [],
      "source": [
        "print(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPjZ3lEHULQI"
      },
      "source": [
        "## Step5: ①各種フォーマット（ppt, word等）で資料を作成する: pptの参考情報"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8TPqPpF1k1k"
      },
      "outputs": [],
      "source": [
        "def generate_presentation(input_str,  output_filename=\"meeting_agenda_presentation.pptx\"):\n",
        "    from langchain.prompts import PromptTemplate\n",
        "    from langchain_openai import ChatOpenAI\n",
        "    from pptx import Presentation\n",
        "    from pptx.util import Inches, Pt\n",
        "    import os\n",
        "\n",
        "    # OpenAI APIキーの設定（環境変数を使用）\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-KlvCw7CI3UmHnyztvFslkMT0E8pLhfnA4HXB6uBiD8T3BlbkFJNI2-wy1yA1PkA_xuM5HSS1-ltrwvJaupbKvtE51fwA\"\n",
        "\n",
        "    # 入力文字列から action と input_data をパース\n",
        "    lines = input_str.strip().split('\\n')\n",
        "    action = ''\n",
        "    input_data = ''\n",
        "    for line in lines:\n",
        "        if line.startswith('目的:'):\n",
        "            action = line.replace('目的:', '').strip()\n",
        "        elif line.startswith('情報:'):\n",
        "            input_data = line.replace('情報:', '').strip()\n",
        "        else:\n",
        "            input_data += line.strip() + '\\n'\n",
        "\n",
        "    # OpenAIを使ったチャットモデルを初期化\n",
        "    llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "    # プロンプトテンプレートを修正\n",
        "    slide_template = \"\"\"\n",
        "    あなたはPowerPointを自動作成するエージェントです。以下の入力情報に基づいて、情報をまとめるたたきを作成してください。\n",
        "    各スライドには次の3つの内容を加えてください。１．タイトル、２．リード文（タイトルの下に記載、タイトルで伝えたいメッセージ）、３．リード文を保証する情報の3つ（リード文の下に記載）です。\n",
        "    ただし、最初のスライドには総括となるまとめを記載するようにしてください。\n",
        "\n",
        "    目的:\n",
        "    {action}\n",
        "\n",
        "    入力情報:\n",
        "    {input_data}\n",
        "\n",
        "    各スライドは以下の形式で記述してください：\n",
        "\n",
        "    [タイトル]\n",
        "    [リード文]\n",
        "    [内容]\n",
        "\n",
        "    「スライドタイトル:」や「スライドのリード文:」といった文言は含めないでください。\n",
        "\n",
        "    スライド間は「---」で区切ってください。\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # LangChainのプロンプトテンプレートを作成\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"action\",\"input_data\"],\n",
        "        template=slide_template\n",
        "    )\n",
        "\n",
        "    # プロンプトとLLMを組み合わせてチェーンを作成\n",
        "    chain = prompt | llm\n",
        "\n",
        "    # LLMを使って、スライドの内容を生成\n",
        "    generated_content = chain.invoke({\"action\":action, \"input_data\": input_data})\n",
        "\n",
        "    # AIMessageオブジェクトからテキストを取得\n",
        "    content_text = generated_content.content\n",
        "\n",
        "    # 生成されたスライドの内容をprint文で確認\n",
        "    print(f\"生成されたスライドの内容:\\n{content_text}\")\n",
        "\n",
        "    # PowerPointの自動生成\n",
        "    def create_presentation(content):\n",
        "        # 新しいプレゼンテーションを作成\n",
        "        prs = Presentation()\n",
        "\n",
        "        # 各スライドの情報を生成された内容から取得\n",
        "        slides_info = content.split(\"---\")\n",
        "\n",
        "        for slide_info in slides_info:\n",
        "            if slide_info.strip():  # 空白のみの行を無視\n",
        "                slide_lines = slide_info.strip().split(\"\\n\", 2)\n",
        "                if len(slide_lines) >= 2:\n",
        "                    slide_title = slide_lines[0].strip()\n",
        "                    lead_sentence = slide_lines[1].strip()\n",
        "                    components = slide_lines[2].strip() if len(slide_lines) > 2 else \"\"\n",
        "\n",
        "                    # 不要な文言を削除\n",
        "                    for prefix in [\"スライドタイトル:\", \"タイトル:\"]:\n",
        "                        if slide_title.startswith(prefix):\n",
        "                            slide_title = slide_title.replace(prefix, \"\").strip()\n",
        "                    for prefix in [\"リード文:\", \"スライドのリード文:\"]:\n",
        "                        if lead_sentence.startswith(prefix):\n",
        "                            lead_sentence = lead_sentence.replace(prefix, \"\").strip()\n",
        "\n",
        "                    # リード文内の行頭のハイフンを削除\n",
        "                    lead_sentence = re.sub(r'^\\s*-\\s*', '', lead_sentence, flags=re.MULTILINE)\n",
        "\n",
        "                    # 新しいスライドを作成\n",
        "                    slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
        "\n",
        "                    # タイトルを設定\n",
        "                    title = slide.shapes.title\n",
        "                    title.text = slide_title\n",
        "\n",
        "                    # コンテンツプレースホルダーを取得\n",
        "                    content_placeholder = slide.placeholders[1]\n",
        "                    text_frame = content_placeholder.text_frame\n",
        "                    text_frame.clear()\n",
        "\n",
        "                    # リード文を追加（大きめのフォントサイズ、箇条書きなし）\n",
        "                    p_lead = text_frame.paragraphs[0]\n",
        "                    p_lead.text = lead_sentence\n",
        "                    p_lead.font.size = Pt(24)  # リード文のフォントサイズを設定\n",
        "                    p_lead.level = 0  # レベルを0に設定して箇条書きを無効にする\n",
        "\n",
        "                    # 構成要素を追加（小さめのフォントサイズ、箇条書きあり）\n",
        "                    if components:\n",
        "                        # 構成要素を行ごとに分割\n",
        "                        components = re.sub(r'^\\s*-\\s*', '', components, flags=re.MULTILINE)\n",
        "                        component_lines = components.strip().split('\\n')\n",
        "                        for line in component_lines:\n",
        "                            p_component = text_frame.add_paragraph()\n",
        "                            p_component.text = line.strip()\n",
        "                            p_component.font.size = Pt(18)  # 構成要素のフォントサイズを設定\n",
        "                            p_component.level = 1  # レベルを1に設定して箇条書きを適用\n",
        "\n",
        "            else:\n",
        "                continue  # 空のスライド情報をスキップ\n",
        "\n",
        "        # プレゼンテーションを保存\n",
        "        prs.save(output_filename)\n",
        "\n",
        "    # プレゼンテーションを作成\n",
        "    create_presentation(content_text)\n",
        "\n",
        "    print(\"プレゼンテーションが作成されました。ファイル名: {}\".format(output_filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYENwa_C2LPi",
        "outputId": "2839b82c-725f-4a7a-e3cb-8182bc79cdf7"
      },
      "outputs": [],
      "source": [
        "generate_presentation(input_data, output_filename=\"my_presentation.pptx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si4Q9acJMzXi"
      },
      "source": [
        "## Step5: ②各種フォーマット（ppt, word等）で資料を作成する: wordの参考情報"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6arboL3sQ1oP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from docx import Document\n",
        "from docx.shared import Pt, RGBColor  # RGBColorをインポート\n",
        "\n",
        "def generate_word_document(input_str, output_filename=\"generated_document.docx\"):\n",
        "    # OpenAI APIキーの設定（環境変数を使用）\n",
        "    api_key = os.environ.get('OPENAI_API_KEY')\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 'OPENAI_API_KEY' を設定してください。\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # OpenAIを使ったチャットモデルを初期化\n",
        "    llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "    # 入力文字列から action と input_data をパース\n",
        "    lines = input_str.strip().split('\\n')\n",
        "    action = ''\n",
        "    input_data = ''\n",
        "    for line in lines:\n",
        "        if line.startswith('目的:'):\n",
        "            action = line.replace('目的:', '').strip()\n",
        "        elif line.startswith('情報:'):\n",
        "            input_data = line.replace('情報:', '').strip()\n",
        "        else:\n",
        "            input_data += line.strip() + '\\n'\n",
        "\n",
        "    # プロンプトテンプレートを修正\n",
        "    document_template = \"\"\"\n",
        "    あなたはWord文書を自動作成するエージェントです。以下の入力情報に基づいて、情報をまとめた文書を作成してください。\n",
        "    各セクションに含める内容は、見出しとリード文（見出しの下に記載、見出しで伝えたいメッセージ）、そしてリード文を補足する情報の3つです。\n",
        "    ただし、最初のセクションには総括となるまとめを記載するようにしてください。\n",
        "\n",
        "    目的:\n",
        "    {action}\n",
        "\n",
        "    入力情報:\n",
        "    {input_data}\n",
        "\n",
        "    各セクションは以下の形式で記述してください：\n",
        "\n",
        "    [見出し]\n",
        "    [リード文]\n",
        "    [内容]\n",
        "\n",
        "    「セクション見出し:」や「リード文:」といった文言は含めないでください。\n",
        "\n",
        "    セクション間は「---」で区切ってください。\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # LangChainのプロンプトテンプレートを作成\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"action\",\"input_data\"],\n",
        "        template=document_template\n",
        "    )\n",
        "\n",
        "    # プロンプトとLLMを組み合わせてチェーンを作成\n",
        "    chain = prompt | llm\n",
        "\n",
        "    # LLMを使って、文書の内容を生成\n",
        "    generated_content = chain.invoke({\"action\":action, \"input_data\": input_data})\n",
        "\n",
        "    # AIMessageオブジェクトからテキストを取得\n",
        "    content_text = generated_content.content\n",
        "\n",
        "    # 生成されたコンテンツをprintで確認\n",
        "    print(\"生成されたコンテンツ:\\n\", content_text)\n",
        "\n",
        "    # Word文書の作成関数\n",
        "    def create_document(content):\n",
        "        # 新しいWord文書を作成\n",
        "        doc = Document()\n",
        "\n",
        "        # 各セクションの情報を生成された内容から取得\n",
        "        sections_info = content.split(\"---\")\n",
        "\n",
        "        for section_info in sections_info:\n",
        "            if section_info.strip():  # 空白のみの行を無視\n",
        "                section_lines = section_info.strip().split(\"\\n\", 2)\n",
        "                if len(section_lines) >= 2:\n",
        "                    heading = section_lines[0].strip()\n",
        "                    lead_sentence = section_lines[1].strip()\n",
        "                    components = section_lines[2].strip() if len(section_lines) > 2 else \"\"\n",
        "\n",
        "                    # 不要な文言を削除\n",
        "                    for prefix in [\"セクション見出し:\", \"見出し:\"]:\n",
        "                        if heading.startswith(prefix):\n",
        "                            heading = heading.replace(prefix, \"\").strip()\n",
        "                    for prefix in [\"リード文:\", \"セクションのリード文:\"]:\n",
        "                        if lead_sentence.startswith(prefix):\n",
        "                            lead_sentence = lead_sentence.replace(prefix, \"\").strip()\n",
        "\n",
        "                    # リード文内の行頭のハイフンを削除\n",
        "                    lead_sentence = re.sub(r'^\\s*-\\s*', '', lead_sentence, flags=re.MULTILINE)\n",
        "\n",
        "                    # 見出しを追加（レベル1）\n",
        "                    heading1 = doc.add_heading(heading, level=1)\n",
        "                    # 見出しの文字色を黒に設定\n",
        "                    for run in heading1.runs:\n",
        "                        run.font.color.rgb = RGBColor(0, 0, 0)\n",
        "\n",
        "                    # リード文を追加（レベル2の見出しとして追加）\n",
        "                    heading2 = doc.add_heading(lead_sentence, level=2)\n",
        "                    # リード文の文字色を黒に設定\n",
        "                    for run in heading2.runs:\n",
        "                        run.font.color.rgb = RGBColor(0, 0, 0)\n",
        "\n",
        "                    # 構成要素を追加（通常の段落）\n",
        "                    if components:\n",
        "                        # 構成要素を行ごとに分割\n",
        "                        components = re.sub(r'^\\s*-\\s*', '', components, flags=re.MULTILINE)\n",
        "                        component_lines = components.strip().split('\\n')\n",
        "                        for line in component_lines:\n",
        "                            p_component = doc.add_paragraph()\n",
        "                            run_component = p_component.add_run(line.strip())\n",
        "                            run_component.font.size = Pt(11)\n",
        "                            # 構成要素の文字色を黒に設定\n",
        "                            run_component.font.color.rgb = RGBColor(0, 0, 0)\n",
        "\n",
        "                else:\n",
        "                    continue  # 空のセクション情報をスキップ\n",
        "\n",
        "        # 文書を保存\n",
        "        doc.save(output_filename)\n",
        "\n",
        "    # Word文書を作成\n",
        "    create_document(content_text)\n",
        "\n",
        "    print(\"Word文書が作成されました。ファイル名: {}\".format(output_filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8pUFTOORUb0",
        "outputId": "4f876ca3-6056-47dc-9498-2b3174bf338c"
      },
      "outputs": [],
      "source": [
        "generate_word_document(input_data, output_filename=\"generated_document.docx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbfQC7h5M5W1"
      },
      "source": [
        "## Step5: ③各種フォーマット（ppt, word等）で資料を作成する: mailの参考情報"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVFTu1xPWzh4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "def generate_email_content(input_str):\n",
        "    # OpenAI APIキーの設定（環境変数を使用）\n",
        "    api_key = os.environ.get('OPENAI_API_KEY')\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 'OPENAI_API_KEY' を設定してください。\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # OpenAIを使ったチャットモデルを初期化\n",
        "    llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "    # 入力文字列から action と input_data をパース\n",
        "    lines = input_str.strip().split('\\n')\n",
        "    action = ''\n",
        "    input_data = ''\n",
        "    for line in lines:\n",
        "        if line.startswith('目的:'):\n",
        "            action = line.replace('目的:', '').strip()\n",
        "        elif line.startswith('情報:'):\n",
        "            input_data = line.replace('情報:', '').strip()\n",
        "        else:\n",
        "            input_data += line.strip() + '\\n'\n",
        "\n",
        "    # メール作成用のプロンプトテンプレート\n",
        "    email_template = \"\"\"\n",
        "    あなたはビジネス文書の作成に長けたプロフェッショナルです。以下の入力情報に基づいて、関連部署に報告するメール文を作成してください。\n",
        "\n",
        "    **要件:**\n",
        "    - 件名は適切なものを設定してください。\n",
        "    - メール本文には以下の点を含めてください:\n",
        "        - 敬語を使用し、丁寧な表現を心がける\n",
        "        - 報告内容の概要を簡潔に述べる\n",
        "        - 添付資料がある場合は、その旨を記載する\n",
        "        - 必要に応じて今後のアクションや問い合わせ先を明記する\n",
        "\n",
        "    **入力情報:**\n",
        "    {input_data}\n",
        "\n",
        "    **出力形式:**\n",
        "    ```\n",
        "    件名：\n",
        "\n",
        "    [メール本文]\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    # LangChainのプロンプトテンプレートを作成\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"input_data\"],\n",
        "        template=email_template\n",
        "    )\n",
        "\n",
        "    # プロンプトとLLMを組み合わせてチェーンを作成\n",
        "    chain = prompt | llm\n",
        "\n",
        "    # LLMを使って、メールの内容を生成\n",
        "    generated_email = chain.invoke({\n",
        "        \"input_data\": input_data\n",
        "    })\n",
        "\n",
        "    # AIMessageオブジェクトからテキストを取得\n",
        "    email_text = generated_email.content\n",
        "\n",
        "    # 結果を表示\n",
        "    print(\"生成されたメールの内容:\")\n",
        "    print(email_text)\n",
        "\n",
        "    # 必要に応じて、メールの内容をファイルに保存することも可能です\n",
        "    # with open(\"email_content.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    #     f.write(email_text)\n",
        "\n",
        "    return email_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Su4ySlggXFNS",
        "outputId": "2931d094-0c05-4159-d042-ff9b9a09aaa5"
      },
      "outputs": [],
      "source": [
        "# 出来上がったものをフォーマットを作成する\n",
        "generate_email_content(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN1twoxwFdCD"
      },
      "source": [
        "# おまけ：エージェントによる資料作成の自動化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3E1Vz8AF36m"
      },
      "outputs": [],
      "source": [
        "#資料作成エージェント（先ほど作成したコードの実行）\n",
        "def agent_function(input_str):\n",
        "    tools = [\n",
        "          Tool(\n",
        "              name=\"generate_presentation\",\n",
        "              func=generate_presentation,\n",
        "              description=\"このツールはインプットを受け取り、含まれたアクションとそのための情報を取得します。それらを元に、まとめ資料をpptで作成します。\",\n",
        "          ),\n",
        "          Tool(\n",
        "              name = \"generate_word_document\",\n",
        "              func=generate_word_document,\n",
        "              description=\"このツールはインプットを受け取り、含まれたアクションとそのための情報を取得します。それらを元に、まとめ資料をwordで作成します。\",\n",
        "          ),\n",
        "          Tool(\n",
        "              name = \"generate_email_content\",\n",
        "              func=generate_email_content,\n",
        "              description=\"このツールはインプットを受け取り、含まれたアクションとそのための情報を取得します。それらを元に、まとめ報告するメール文章を作成します。\"\n",
        "          ),\n",
        "      ]\n",
        "    chat_agent = initialize_agent(\n",
        "        tools,\n",
        "        llm=ChatOpenAI(temperature=0, model=model_name),\n",
        "        agent = \"zero-shot-react-description\",\n",
        "        verbose=True,\n",
        "        system_message=\"あなたは親切なアシスタントです。インプットされた目的と情報を元に\",\n",
        "    )\n",
        "\n",
        "    # エージェントへの入力を作成\n",
        "    agent_input = f\"各種関係者に目的に応じた情報を共有したいので、ppt,word,メール作成を手伝ってください。:\\n目的：{action}\\n情報：{rag_result} \"\n",
        "    result = chat_agent.run(agent_input)\n",
        "    result_ja = translate_to_japanese(result)\n",
        "    return result_ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmjhl1Xxh4FY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kebkpy5soqh0",
        "outputId": "095dede3-08a4-4ef6-8a0b-5ca50fc16ecd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "YS1rrZjIeQsw",
        "outputId": "2efcaac5-da8f-4e14-d1ee-b0c6189d86a7"
      },
      "outputs": [],
      "source": [
        "agent_function(input_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8xzlhtJA1Nc",
        "outputId": "7847074a-d4bd-4457-b1a3-d0da7d724a8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "BsIPY9OiAknM",
        "outputId": "2094683b-1ad1-4c4a-8d69-8dc1823b72aa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "Ck9KalAUAocG",
        "outputId": "b50a10e3-8276-4c3e-a61e-865707c667c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OolD0_dtAtJA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrqIMKDNAuzs",
        "outputId": "37dc7d83-85ac-4c5f-f425-64f46a431798"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQGn07u6Awjm",
        "outputId": "579c6d82-eece-40f6-83aa-f44abb5ef538"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_8WHeS3AyMg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AQ7bVuMdA1R5",
        "outputId": "4f80336c-0d87-43ec-a8c7-3eb8aa5fe46b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPyEl0gsJVec"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
